{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df Shape:  (569, 27)\n",
      "Train_x Shape:  (455, 26)\n",
      "Train_y Shape:  (455,)\n",
      "Test_x Shape:  (114, 26)\n",
      "Test_y Shape:  (114,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "df = pd.read_csv(\"Breastdata.csv\")\n",
    "\n",
    "df= df.drop('concave points_worst', axis = 1)\n",
    "df= df.drop('concave points_mean', axis = 1)\n",
    "df= df.drop('radius_worst', axis = 1)\n",
    "df= df.drop('perimeter_worst', axis = 1)\n",
    "\n",
    "df= df.drop('id', axis = 1)\n",
    "\n",
    "df['diagnosis']=df['diagnosis'].apply(lambda x: 1 if x == 'M' else 0 )\n",
    "\n",
    "\n",
    "df.dropna(inplace= True)\n",
    "print (\"df Shape: \", df.shape)\n",
    "df = pd.get_dummies(df)\n",
    "labels = np.array(df['diagnosis'])\n",
    "df= df.drop('diagnosis', axis = 1)\n",
    "df_list = list(df.columns)\n",
    "\n",
    "#df.isnull().sum()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df, labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print (\"Train_x Shape: \",train_x.shape)\n",
    "print (\"Train_y Shape: \", train_y.shape)\n",
    "print (\"Test_x Shape: \", test_x.shape)\n",
    "print (\"Test_y Shape: \", test_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9450\n",
      "Mean of Accuracy of kfold cross validation results:0.8824\n",
      "Confusion Matrix:\n",
      "[[69  2]\n",
      " [ 7 36]]\n",
      "Accuracy: 0.9211\n",
      "AUC Score:0.9045\n",
      "Precision:0.9474\n",
      "Recall:0.8372\n",
      "F1 Score:0.8889\n",
      "                      importance\n",
      "area_worst              0.840670\n",
      "compactness_worst       0.117026\n",
      "concavity_mean          0.042304\n",
      "radius_mean             0.000000\n",
      "compactness_se          0.000000\n",
      "symmetry_worst          0.000000\n",
      "concavity_worst         0.000000\n",
      "smoothness_worst        0.000000\n",
      "texture_worst           0.000000\n",
      "fractal_dimension_se    0.000000\n"
     ]
    }
   ],
   "source": [
    "seed_1 = 15\n",
    "# Create Decision Tree classifer object with max_depth = 2 and criterion = gini\n",
    "clf = DecisionTreeClassifier(random_state = seed_1,max_depth = 2,criterion = \"gini\")\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = clf.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances_DTC.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9465\n",
      "Mean of Accuracy of kfold cross validation results:0.9350\n",
      "Confusion Matrix:\n",
      "[[68  3]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9474\n",
      "AUC Score:0.9440\n",
      "Precision:0.9302\n",
      "Recall:0.9302\n",
      "F1 Score:0.9302\n",
      "                         importance\n",
      "area_worst                 0.724879\n",
      "compactness_worst          0.098404\n",
      "smoothness_mean            0.038581\n",
      "concavity_mean             0.035573\n",
      "texture_mean               0.031073\n",
      "texture_worst              0.023971\n",
      "area_mean                  0.016553\n",
      "concavity_worst            0.013211\n",
      "fractal_dimension_worst    0.008878\n",
      "radius_se                  0.008878\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object with max_depth = 4 and criterion = gini\n",
    "clf = DecisionTreeClassifier(random_state = seed_1,max_depth = 4,criterion = \"gini\")\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = clf.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances_DTC.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9331\n",
      "Mean of Accuracy of kfold cross validation results:0.9263\n",
      "Confusion Matrix:\n",
      "[[65  6]\n",
      " [ 4 39]]\n",
      "Accuracy: 0.9123\n",
      "AUC Score:0.9112\n",
      "Precision:0.8667\n",
      "Recall:0.9070\n",
      "F1 Score:0.8864\n",
      "                   importance\n",
      "area_worst           0.697739\n",
      "compactness_worst    0.092748\n",
      "texture_worst        0.045713\n",
      "smoothness_mean      0.036363\n",
      "concavity_mean       0.033528\n",
      "texture_mean         0.029287\n",
      "compactness_se       0.015899\n",
      "area_mean            0.015601\n",
      "concavity_worst      0.012452\n",
      "radius_mean          0.011296\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object with max_depth = 8 and criterion = gini\n",
    "clf = DecisionTreeClassifier(random_state = seed_1,max_depth = 8,criterion = \"gini\")\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = clf.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_DTC.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9549\n",
      "Mean of Accuracy of kfold cross validation results:0.8965\n",
      "Confusion Matrix:\n",
      "[[69  2]\n",
      " [ 6 37]]\n",
      "Accuracy: 0.9298\n",
      "AUC Score:0.9161\n",
      "Precision:0.9487\n",
      "Recall:0.8605\n",
      "F1 Score:0.9024\n",
      "                      importance\n",
      "area_worst              0.755866\n",
      "concavity_worst         0.154771\n",
      "concavity_mean          0.089363\n",
      "radius_mean             0.000000\n",
      "compactness_se          0.000000\n",
      "symmetry_worst          0.000000\n",
      "compactness_worst       0.000000\n",
      "smoothness_worst        0.000000\n",
      "texture_worst           0.000000\n",
      "fractal_dimension_se    0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create Decision Tree classifer object with max_depth = 2 and criterion = entropy\n",
    "clf = DecisionTreeClassifier(random_state = seed_1,max_depth = 2,criterion = \"entropy\")\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = clf.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_DTC.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9608\n",
      "Mean of Accuracy of kfold cross validation results:0.9456\n",
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9386\n",
      "AUC Score:0.9369\n",
      "Precision:0.9091\n",
      "Recall:0.9302\n",
      "F1 Score:0.9195\n",
      "                         importance\n",
      "area_worst                 0.624179\n",
      "concavity_worst            0.122762\n",
      "concavity_mean             0.070881\n",
      "smoothness_worst           0.043117\n",
      "fractal_dimension_se       0.039194\n",
      "concave points_se          0.032907\n",
      "texture_mean               0.028292\n",
      "texture_worst              0.014676\n",
      "radius_mean                0.012819\n",
      "fractal_dimension_worst    0.011171\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object with max_depth = 4 and criterion = entropy\n",
    "clf = DecisionTreeClassifier(random_state = seed_1,max_depth = 4,criterion = \"entropy\")\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "\n",
    "clf = clf.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = clf.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_DTC.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9441\n",
      "Mean of Accuracy of kfold cross validation results:0.9421\n",
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9386\n",
      "AUC Score:0.9369\n",
      "Precision:0.9091\n",
      "Recall:0.9302\n",
      "F1 Score:0.9195\n",
      "                      importance\n",
      "area_worst              0.571840\n",
      "concavity_worst         0.114935\n",
      "concavity_mean          0.066362\n",
      "smoothness_worst        0.050827\n",
      "fractal_dimension_se    0.036695\n",
      "perimeter_mean          0.032303\n",
      "concave points_se       0.030809\n",
      "texture_worst           0.030236\n",
      "texture_mean            0.026488\n",
      "perimeter_se            0.013552\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object with max_depth = 8 and criterion = entropy\n",
    "clf = DecisionTreeClassifier(random_state = seed_1,max_depth = 8,criterion = \"entropy\")\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(clf, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = clf.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_DTC.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9386\n",
      "AUC Score:0.9369\n",
      "Precision:0.9091\n",
      "Recall:0.9302\n",
      "F1 Score:0.9195\n",
      "                      importance\n",
      "area_worst              0.571840\n",
      "concavity_worst         0.114935\n",
      "concavity_mean          0.066362\n",
      "smoothness_worst        0.050827\n",
      "fractal_dimension_se    0.036695\n",
      "perimeter_mean          0.032303\n",
      "concave points_se       0.030809\n",
      "texture_worst           0.030236\n",
      "texture_mean            0.026488\n",
      "perimeter_se            0.013552\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9608\n",
      "Mean of Accuracy of kfold cross validation results:0.9456\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"criterion\" : [\"entropy\", \"gini\"], \n",
    "              \"max_depth\" : [2,4,8,16],\n",
    "              \"min_samples_split\" : [2,3,4,5,6]\n",
    "             }\n",
    "#grid search when scoring is accuracy\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(random_state = seed_1),param_grid = parameters,scoring = \"accuracy\",cv = 10,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_DTC.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
      "Confusion Matrix:\n",
      "[[69  2]\n",
      " [ 6 37]]\n",
      "Accuracy: 0.9298\n",
      "AUC Score:0.9161\n",
      "Precision:0.9487\n",
      "Recall:0.8605\n",
      "F1 Score:0.9024\n",
      "                      importance\n",
      "area_worst              0.571840\n",
      "concavity_worst         0.114935\n",
      "concavity_mean          0.066362\n",
      "smoothness_worst        0.050827\n",
      "fractal_dimension_se    0.036695\n",
      "perimeter_mean          0.032303\n",
      "concave points_se       0.030809\n",
      "texture_worst           0.030236\n",
      "texture_mean            0.026488\n",
      "perimeter_se            0.013552\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9549\n",
      "Mean of Accuracy of kfold cross validation results:0.8965\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"criterion\" : [\"entropy\", \"gini\"], \n",
    "              \"max_depth\" : [2,4,8,16],\n",
    "              \"min_samples_split\" : [2,3,4,5,6]\n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = DecisionTreeClassifier(random_state = seed_1),param_grid = parameters,scoring = \"roc_auc\",cv = 10,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_DTC = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_DTC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_DTC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_DTC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_DTC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_DTC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_DTC))\n",
    "\n",
    "feature_importances_DTC = pd.DataFrame(clf.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_DTC.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9904\n",
      "Mean of Accuracy of kfold cross validation results:0.9561\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9649\n",
      "AUC Score:0.9581\n",
      "Precision:0.9756\n",
      "Recall:0.9302\n",
      "F1 Score:0.9524\n",
      "                   importance\n",
      "area_worst           0.599467\n",
      "concavity_mean       0.112651\n",
      "concavity_worst      0.054494\n",
      "texture_mean         0.041440\n",
      "compactness_worst    0.037755\n",
      "texture_worst        0.031168\n",
      "smoothness_worst     0.022508\n",
      "symmetry_worst       0.014221\n",
      "smoothness_mean      0.012453\n",
      "radius_se            0.010548\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection \n",
    "\n",
    "seed = 8\n",
    "seed_1 = 15\n",
    "\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "# Create Decision Tree classifer object with max_depth = 4 and criterion = gini\n",
    "clf2 = DecisionTreeClassifier(random_state = seed_1,max_depth = 4,criterion = \"entropy\")\n",
    "bgc = BaggingClassifier(base_estimator=clf2, n_estimators=100, random_state=seed_1,bootstrap = True)\n",
    "\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(bgc, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(bgc, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "# Train Bagging Classifer\n",
    "bgc = bgc.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_BC = bgc.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_BC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_BC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_BC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_BC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_BC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_BC))\n",
    "\n",
    "featimp = np.mean([\n",
    "    tree.feature_importances_ for tree in bgc.estimators_\n",
    "], axis=0)\n",
    "\n",
    "feature_importances_BC = pd.DataFrame(featimp,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances_BC.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'bootstrap_features': True, 'max_samples': 0.6, 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9737\n",
      "AUC Score:0.9651\n",
      "Precision:1.0000\n",
      "Recall:0.9302\n",
      "F1 Score:0.9639\n",
      "                         importance\n",
      "smoothness_worst           0.056529\n",
      "smoothness_se              0.054568\n",
      "fractal_dimension_mean     0.052405\n",
      "concavity_se               0.051882\n",
      "fractal_dimension_worst    0.046055\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9903\n",
      "Mean of Accuracy of kfold cross validation results:0.9579\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"max_samples\" : [0.6,0.8,1],\n",
    "              \"bootstrap\": [True,False],\n",
    "              \"bootstrap_features\":[True,False]\n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = bgc,param_grid = parameters,scoring = \"accuracy\",cv = 5,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_BC = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_BC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_BC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_BC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_BC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_BC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_BC))\n",
    "\n",
    "featimp = np.mean([\n",
    "    tree.feature_importances_ for tree in best_model.estimators_\n",
    "], axis=0)\n",
    "\n",
    "feature_importances_BC = pd.DataFrame(featimp,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances_BC.head())\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'bootstrap_features': True, 'max_samples': 0.8, 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9649\n",
      "AUC Score:0.9581\n",
      "Precision:0.9756\n",
      "Recall:0.9302\n",
      "F1 Score:0.9524\n",
      "                         importance\n",
      "smoothness_worst           0.065241\n",
      "fractal_dimension_mean     0.062554\n",
      "concavity_se               0.055346\n",
      "concavity_worst            0.053217\n",
      "fractal_dimension_worst    0.052543\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9905\n",
      "Mean of Accuracy of kfold cross validation results:0.9579\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"max_samples\" : [0.6,0.8,1],\n",
    "              \"bootstrap\": [True,False],\n",
    "              \"bootstrap_features\":[True,False]\n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = bgc,param_grid = parameters,scoring = \"roc_auc\",cv = 5,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_BC = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_BC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_BC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_BC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_BC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_BC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_BC))\n",
    "\n",
    "featimp = np.mean([\n",
    "    tree.feature_importances_ for tree in best_model.estimators_\n",
    "], axis=0)\n",
    "\n",
    "feature_importances_BC = pd.DataFrame(featimp,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances_BC.head())\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9865\n",
      "Mean of Accuracy of kfold cross validation results:0.9579\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9649\n",
      "AUC Score:0.9581\n",
      "Precision:0.9756\n",
      "Recall:0.9302\n",
      "F1 Score:0.9524\n",
      "                  importance\n",
      "perimeter_mean      0.179203\n",
      "area_se             0.172862\n",
      "concavity_mean      0.126308\n",
      "compactness_mean    0.085659\n",
      "concavity_worst     0.077190\n",
      "area_worst          0.060078\n",
      "area_mean           0.039746\n",
      "perimeter_se        0.035574\n",
      "texture_mean        0.026540\n",
      "symmetry_worst      0.025045\n"
     ]
    }
   ],
   "source": [
    "seed = 8\n",
    "seed_1 = 15\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=seed_1)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(rfc, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(rfc, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "# Train Bagging Classifer\n",
    "rfc = rfc.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_RFC = rfc.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_RFC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_RFC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_RFC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_RFC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_RFC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_RFC))\n",
    "\n",
    "feature_importances_RFC = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_RFC.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   53.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 2 41]]\n",
      "Accuracy: 0.9737\n",
      "AUC Score:0.9697\n",
      "Precision:0.9762\n",
      "Recall:0.9535\n",
      "F1 Score:0.9647\n",
      "                         importance\n",
      "smoothness_worst           0.065241\n",
      "fractal_dimension_mean     0.062554\n",
      "concavity_se               0.055346\n",
      "concavity_worst            0.053217\n",
      "fractal_dimension_worst    0.052543\n",
      "texture_worst              0.046775\n",
      "smoothness_se              0.046534\n",
      "radius_mean                0.043660\n",
      "compactness_mean           0.041512\n",
      "area_worst                 0.040747\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9925\n",
      "Mean of Accuracy of kfold cross validation results:0.9631\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"criterion\" : [\"gini\",\"entropy\"],\n",
    "              \"max_features\" : [\"auto\",\"log2\",\"sqrt\"],\n",
    "              \"max_depth\":[4,8,None] \n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = rfc,param_grid = parameters,scoring = \"accuracy\",cv = 3,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_RFC = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_RFC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_RFC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_RFC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_RFC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_RFC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_RFC))\n",
    "\n",
    "feature_importances_RFC = pd.DataFrame(best_model.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances_BC.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   54.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 1000}\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 2 41]]\n",
      "Accuracy: 0.9737\n",
      "AUC Score:0.9697\n",
      "Precision:0.9762\n",
      "Recall:0.9535\n",
      "F1 Score:0.9647\n",
      "                         importance\n",
      "smoothness_worst           0.065241\n",
      "fractal_dimension_mean     0.062554\n",
      "concavity_se               0.055346\n",
      "concavity_worst            0.053217\n",
      "fractal_dimension_worst    0.052543\n",
      "texture_worst              0.046775\n",
      "smoothness_se              0.046534\n",
      "radius_mean                0.043660\n",
      "compactness_mean           0.041512\n",
      "area_worst                 0.040747\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9923\n",
      "Mean of Accuracy of kfold cross validation results:0.9596\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"criterion\" : [\"gini\",\"entropy\"],\n",
    "              \"max_features\" : [\"auto\",\"log2\",\"sqrt\"],\n",
    "              \"max_depth\":[4,8,None] \n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = rfc,param_grid = parameters,scoring = \"roc_auc\",cv = 3,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_RFC = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_RFC))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_RFC))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_RFC))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_RFC))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_RFC))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_RFC))\n",
    "\n",
    "feature_importances_RFC = pd.DataFrame(best_model.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importances_BC.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9924\n",
      "Mean of Accuracy of kfold cross validation results:0.9701\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9649\n",
      "AUC Score:0.9581\n",
      "Precision:0.9756\n",
      "Recall:0.9302\n",
      "F1 Score:0.9524\n",
      "                   importance\n",
      "area_worst               0.14\n",
      "smoothness_worst         0.10\n",
      "texture_mean             0.08\n",
      "compactness_se           0.08\n",
      "symmetry_worst           0.06\n",
      "concavity_worst          0.06\n",
      "concavity_mean           0.06\n",
      "concave points_se        0.04\n",
      "symmetry_mean            0.04\n",
      "texture_worst            0.04\n"
     ]
    }
   ],
   "source": [
    "seed = 8\n",
    "seed_1 = 15\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "\n",
    "ada = AdaBoostClassifier(random_state = seed_1)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(ada, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(ada, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "# Train Bagging Classifer\n",
    "ada = ada.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_ada = rfc.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_ada))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_ada))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_ada))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_ada))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_ada))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_ada))\n",
    "\n",
    "feature_importances_ada = pd.DataFrame(ada.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_ada.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   42.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 1000}\n",
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 2 41]]\n",
      "Accuracy: 0.9825\n",
      "AUC Score:0.9767\n",
      "Precision:1.0000\n",
      "Recall:0.9535\n",
      "F1 Score:0.9762\n",
      "                   importance\n",
      "area_worst               0.14\n",
      "smoothness_worst         0.10\n",
      "texture_mean             0.08\n",
      "compactness_se           0.08\n",
      "symmetry_worst           0.06\n",
      "concavity_worst          0.06\n",
      "concavity_mean           0.06\n",
      "concave points_se        0.04\n",
      "symmetry_mean            0.04\n",
      "texture_worst            0.04\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9973\n",
      "Mean of Accuracy of kfold cross validation results:0.9789\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"learning_rate\" : [0.01,0.1,0.3,0.5,0.7,1],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"]\n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = ada,param_grid = parameters,scoring = \"accuracy\",cv = 3,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_ada = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_ada))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_ada))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_ada))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_ada))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_ada))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_ada))\n",
    "\n",
    "feature_importances_ada = pd.DataFrame(ada.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_ada.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   40.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 1000}\n",
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 2 41]]\n",
      "Accuracy: 0.9825\n",
      "AUC Score:0.9767\n",
      "Precision:1.0000\n",
      "Recall:0.9535\n",
      "F1 Score:0.9762\n",
      "                   importance\n",
      "area_worst               0.14\n",
      "smoothness_worst         0.10\n",
      "texture_mean             0.08\n",
      "compactness_se           0.08\n",
      "symmetry_worst           0.06\n",
      "concavity_worst          0.06\n",
      "concavity_mean           0.06\n",
      "concave points_se        0.04\n",
      "symmetry_mean            0.04\n",
      "texture_worst            0.04\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9973\n",
      "Mean of Accuracy of kfold cross validation results:0.9789\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"learning_rate\" : [0.01,0.1,0.3,0.5,0.7,1],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"]\n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = ada,param_grid = parameters,scoring = \"roc_auc\",cv = 3,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_ada = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_ada))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_ada))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_ada))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_ada))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_ada))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_ada))\n",
    "\n",
    "feature_importances_ada = pd.DataFrame(ada.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_ada.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Roc_Auc of kfold cross validation results:0.9907\n",
      "Mean of Accuracy of kfold cross validation results:0.9561\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 3 40]]\n",
      "Accuracy: 0.9649\n",
      "AUC Score:0.9581\n",
      "Precision:0.9756\n",
      "Recall:0.9302\n",
      "F1 Score:0.9524\n",
      "                   importance\n",
      "area_worst           0.272352\n",
      "texture_worst        0.108591\n",
      "concavity_worst      0.069642\n",
      "texture_mean         0.051667\n",
      "smoothness_worst     0.049074\n",
      "concavity_mean       0.046772\n",
      "compactness_mean     0.044862\n",
      "perimeter_mean       0.041557\n",
      "symmetry_worst       0.036497\n",
      "compactness_worst    0.033946\n"
     ]
    }
   ],
   "source": [
    "seed = 8\n",
    "seed_1 = 15\n",
    "\n",
    "X = df\n",
    "Y = labels\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state = seed_1)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(gb, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(gb, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())\n",
    "# Train Bagging Classifer\n",
    "gb = gb.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_gb = rfc.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_gb))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_gb))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_gb))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_gb))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_gb))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_gb))\n",
    "\n",
    "feature_importances_ada = pd.DataFrame(gb.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_ada.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1, 'loss': 'exponential', 'max_depth': 3, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 2 41]]\n",
      "Accuracy: 0.9825\n",
      "AUC Score:0.9767\n",
      "Precision:1.0000\n",
      "Recall:0.9535\n",
      "F1 Score:0.9762\n",
      "                      importance\n",
      "area_worst              0.045348\n",
      "texture_worst           0.030113\n",
      "smoothness_worst        0.027925\n",
      "texture_mean            0.025794\n",
      "symmetry_worst          0.024639\n",
      "compactness_se          0.023908\n",
      "compactness_mean        0.022344\n",
      "fractal_dimension_se    0.014514\n",
      "concavity_se            0.014456\n",
      "texture_se              0.014436\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9939\n",
      "Mean of Accuracy of kfold cross validation results:0.9701\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"learning_rate\" : [0.01,0.1,0.3,0.7,1],\n",
    "              \"loss\" : [\"deviance\",\"exponential\"],\n",
    "              \"min_samples_split\" : [2,4,8],\n",
    "              \"max_depth\" : [3,4,8]\n",
    "              \n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = gb,param_grid = parameters,scoring = \"accuracy\",cv = 3,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_gb = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_gb))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_gb))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_gb))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_gb))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_gb))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_gb))\n",
    "\n",
    "feature_importances_gb = pd.DataFrame(best_model.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_gb.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.7, 'loss': 'exponential', 'max_depth': 3, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 2 41]]\n",
      "Accuracy: 0.9825\n",
      "AUC Score:0.9767\n",
      "Precision:1.0000\n",
      "Recall:0.9535\n",
      "F1 Score:0.9762\n",
      "                        importance\n",
      "area_worst                0.068738\n",
      "texture_worst             0.055628\n",
      "compactness_se            0.040899\n",
      "symmetry_worst            0.028879\n",
      "texture_mean              0.025220\n",
      "fractal_dimension_mean    0.022094\n",
      "radius_se                 0.021599\n",
      "concavity_worst           0.021458\n",
      "smoothness_worst          0.016654\n",
      "concavity_mean            0.014798\n",
      "Mean of Roc_Auc of kfold cross validation results:0.9927\n",
      "Mean of Accuracy of kfold cross validation results:0.9666\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_estimators\" : [100,1000], \n",
    "              \"learning_rate\" : [0.01,0.1,0.3,0.7,1],\n",
    "              \"loss\" : [\"deviance\",\"exponential\"],\n",
    "              \"min_samples_split\" : [2,4,8],\n",
    "              \"max_depth\" : [3,4,8]\n",
    "              \n",
    "             }\n",
    "#grid search when scoring is roc_auc score\n",
    "grid_search = GridSearchCV(estimator = gb,param_grid = parameters,scoring = \"roc_auc\",cv = 3,verbose = 1,n_jobs = -1)\n",
    "grid_search = grid_search.fit(train_x,train_y)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model = best_model.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_gb = best_model.predict(test_x)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, y_pred_gb))\n",
    "print(\"Accuracy: %0.4f\"%metrics.accuracy_score(test_y, y_pred_gb))\n",
    "print (\"AUC Score:%0.4f\"%roc_auc_score(test_y, y_pred_gb))\n",
    "print (\"Precision:%0.4f\"%precision_score(test_y, y_pred_gb))\n",
    "print (\"Recall:%0.4f\"%recall_score(test_y, y_pred_gb))\n",
    "print (\"F1 Score:%0.4f\"%f1_score(test_y, y_pred_gb))\n",
    "\n",
    "feature_importances_gb = pd.DataFrame(best_model.feature_importances_,\n",
    "                                   index = train_x.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances_gb.head(10))\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"roc_auc\") \n",
    "print(\"Mean of Roc_Auc of kfold cross validation results:%0.4f\"%results.mean())\n",
    "results = model_selection.cross_val_score(best_model, X, Y, cv = kfold, scoring = \"accuracy\") \n",
    "print(\"Mean of Accuracy of kfold cross validation results:%0.4f\"%results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
